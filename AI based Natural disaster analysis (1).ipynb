{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers \n",
    "\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D \n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our data and performing data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 742 images belonging to 4 classes.\n",
      "Found 198 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = train_datagen.flow_from_directory(r\"C:\\Users\\akhila\\Downloads\\dataset\\dataset\\train_set\",target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode=\"categorical\")\n",
    "\n",
    "x_test = test_datagen.flow_from_directory(r\"C:\\Users\\akhila\\Downloads\\dataset\\dataset\\test_set\",target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 220, 1: 156, 2: 198, 3: 168})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhila\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=4, activation='softmax')) # softmax for more than 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 813,604\n",
      "Trainable params: 813,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "149/149 [==============================] - 36s 242ms/step - loss: 1.2389 - acc: 0.4340 - val_loss: 1.0988 - val_acc: 0.5657\n",
      "Epoch 2/20\n",
      "149/149 [==============================] - 30s 198ms/step - loss: 0.8707 - acc: 0.6307 - val_loss: 0.9361 - val_acc: 0.6667\n",
      "Epoch 3/20\n",
      "149/149 [==============================] - 30s 200ms/step - loss: 0.7493 - acc: 0.7075 - val_loss: 0.7065 - val_acc: 0.7525\n",
      "Epoch 4/20\n",
      "149/149 [==============================] - 28s 187ms/step - loss: 0.6375 - acc: 0.7480 - val_loss: 0.6918 - val_acc: 0.7525\n",
      "Epoch 5/20\n",
      "149/149 [==============================] - 29s 194ms/step - loss: 0.5617 - acc: 0.7925 - val_loss: 0.8709 - val_acc: 0.7121\n",
      "Epoch 6/20\n",
      "149/149 [==============================] - 28s 191ms/step - loss: 0.5710 - acc: 0.7857 - val_loss: 0.6277 - val_acc: 0.7778\n",
      "Epoch 7/20\n",
      "149/149 [==============================] - 28s 188ms/step - loss: 0.4677 - acc: 0.8369 - val_loss: 0.9838 - val_acc: 0.6818\n",
      "Epoch 8/20\n",
      "149/149 [==============================] - 27s 181ms/step - loss: 0.4549 - acc: 0.8167 - val_loss: 0.6981 - val_acc: 0.7727\n",
      "Epoch 9/20\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 0.4146 - acc: 0.8329 - val_loss: 0.7934 - val_acc: 0.7576\n",
      "Epoch 10/20\n",
      "149/149 [==============================] - 28s 191ms/step - loss: 0.4175 - acc: 0.8396 - val_loss: 0.9202 - val_acc: 0.7222\n",
      "Epoch 11/20\n",
      "149/149 [==============================] - 32s 215ms/step - loss: 0.3424 - acc: 0.8679 - val_loss: 0.7109 - val_acc: 0.7980\n",
      "Epoch 12/20\n",
      "149/149 [==============================] - 27s 181ms/step - loss: 0.3644 - acc: 0.8612 - val_loss: 0.7872 - val_acc: 0.7727\n",
      "Epoch 13/20\n",
      "149/149 [==============================] - 30s 204ms/step - loss: 0.2939 - acc: 0.8962 - val_loss: 0.8089 - val_acc: 0.7677\n",
      "Epoch 14/20\n",
      "149/149 [==============================] - 29s 196ms/step - loss: 0.3038 - acc: 0.8881 - val_loss: 0.8988 - val_acc: 0.7677\n",
      "Epoch 15/20\n",
      "149/149 [==============================] - 28s 185ms/step - loss: 0.2423 - acc: 0.8976 - val_loss: 0.9817 - val_acc: 0.7879\n",
      "Epoch 16/20\n",
      "149/149 [==============================] - 30s 199ms/step - loss: 0.2470 - acc: 0.9124 - val_loss: 0.8030 - val_acc: 0.8081\n",
      "Epoch 17/20\n",
      "149/149 [==============================] - 28s 185ms/step - loss: 0.2120 - acc: 0.9218 - val_loss: 0.9294 - val_acc: 0.7879\n",
      "Epoch 18/20\n",
      "149/149 [==============================] - 29s 195ms/step - loss: 0.2385 - acc: 0.9097 - val_loss: 1.0101 - val_acc: 0.7727\n",
      "Epoch 19/20\n",
      "149/149 [==============================] - 29s 198ms/step - loss: 0.1708 - acc: 0.9434 - val_loss: 0.8255 - val_acc: 0.7677\n",
      "Epoch 20/20\n",
      "149/149 [==============================] - 29s 196ms/step - loss: 0.1486 - acc: 0.9380 - val_loss: 1.0777 - val_acc: 0.7828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x269e003c128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=20, validation_data=x_test,validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('disaster.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhila\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\akhila\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "model = load_model(\"disaster.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(r\"E:\\geetanjaliexternship\\cyclone.jpg\",grayscale=False,\n",
    "                     target_size= (64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "pred = model.predict_classes(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cyclone'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterthemes\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/08/9dee6dfd7f2aad6c30282d55c8f495b4dc1e4747b4e2bdbeb80572ddf312/jupyterthemes-0.20.0-py2.py3-none-any.whl\n",
      "Collecting as\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/08/226c133ec497d25a63edb38527c02db093c7d89e6d4cdc91078834486a5d/as-0.1-py3-none-any.whl\n",
      "Collecting jt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement jt (from versions: none)\n",
      "ERROR: No matching distribution found for jt\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyterthemes as jt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'jt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!jt -t monokai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
